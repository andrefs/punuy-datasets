{
  "id": "simverb3500",
  "metadata": {
    "name": "SimVerb-3500",
    "authors": "Daniela Gerz, Ivan Vulic, Felix Hill, Roi Reichart, Anna Korhonen",
    "license": {
      "url": "https://creativecommons.org/licenses/by/4.0/",
      "name": "CC BY 4.0"
    },
    "urls": [
      "https://www.repository.cam.ac.uk/items/8a568201-0fa4-4e54-81b1-f920102492ea"
    ],
    "papers": [
      {
        "title": "SimVerb-3500: A Large-Scale Evaluation Set of Verb Similarity",
        "url": "https://aclanthology.org/D16-1235.pdf"
      }
    ],
    "date": "2016",
    "description": "SimVerb-3500 is a gold standard evaluation resource for semantic similarity of verbs.\n\nWe provide 3500 verb pairs with ratings on a scale 0-10. Here are some examples: to reply / to respond - 9.79; to participate / to join - 5.64; to stay / to leave - 0.17;\n\nSimVerb-3500 covers all normed verb types from the USF free-association database, and provides at least three examples for every VerbNet class.",
    "downloadUrls": [
      "https://www.repository.cam.ac.uk/bitstreams/8b6bfa68-4256-4e2d-9d06-628748b2daea/download"
    ],
    "languages": ["en"],
    "domain": "general",
    "relationTypes": ["similarity"]
  },
  "partitions": [
    {
      "id": "dev",
      "relationType": "similarity",
      "scale": {
        "value": {
          "max": 10,
          "min": 0
        }
      },
      "metrics": {
        "annotators": {
          "total": 11,
          "minEachPair": 10
        },
        "interAnnoAgreement": []
      }
    },
    {
      "id": "test",
      "relationType": "similarity",
      "scale": {
        "value": {
          "max": 10,
          "min": 0
        }
      },
      "metrics": {
        "annotators": {
          "total": 11,
          "minEachPair": 10
        },
        "interAnnoAgreement": []
      }
    },
    {
      "id": "all",
      "relationType": "similarity",
      "scale": {
        "value": {
          "max": 10,
          "min": 0
        }
      },
      "metrics": {
        "annotators": {
          "total": 11,
          "minEachPair": 10
        },
        "interAnnoAgreement": [
          {
            "method": "spearman",
            "value": 0.86,
            "metric": "AMIAA",
            "description": "A complementary measure would smooth individual annotator effects. For this aim, our IAA-2 (mean) measure compares the average correlation of a human rater with the average of all the other raters. [...] SimVerb-3500 obtains [...] ρ = 0.86 (IAA-2) [...]"
          },
          {
            "method": "spearman",
            "value": 0.84,
            "metric": "APIAA",
            "description": "IAA-1 (pairwise) computes the average pairwise Spearman’s ρ correlation between any two raters – a common choice in previous data collection in distributional semantics (Padó et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014; Hill et al., 2015). [...] SimVerb-3500 obtains ρ = 0.84 (IAA-1) [...]"
          }
        ]
      }
    }
  ],
  "originalInstructions": ""
}
